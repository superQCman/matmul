







.version 6.4
.target sm_30
.address_size 64



.visible .entry _Z14matrix_mul_gpuPlS_S_i(
.param .u64 _Z14matrix_mul_gpuPlS_S_i_param_0,
.param .u64 _Z14matrix_mul_gpuPlS_S_i_param_1,
.param .u64 _Z14matrix_mul_gpuPlS_S_i_param_2,
.param .u32 _Z14matrix_mul_gpuPlS_S_i_param_3
)
{
.reg .pred %p<7>;
.reg .b32 %r<35>;
.reg .b64 %rd<73>;


ld.param.u64 %rd17, [_Z14matrix_mul_gpuPlS_S_i_param_0];
ld.param.u64 %rd18, [_Z14matrix_mul_gpuPlS_S_i_param_1];
ld.param.u64 %rd15, [_Z14matrix_mul_gpuPlS_S_i_param_2];
ld.param.u32 %r16, [_Z14matrix_mul_gpuPlS_S_i_param_3];
cvta.to.global.u64 %rd1, %rd18;
cvta.to.global.u64 %rd2, %rd17;
mov.u32 %r1, %tid.y;
mov.u32 %r2, %tid.x;
mov.u64 %rd72, 0;
setp.lt.s32	%p1, %r16, 1;
@%p1 bra BB0_10;

mul.lo.s32 %r3, %r1, %r16;
and.b32 %r20, %r16, 3;
mov.u64 %rd72, 0;
mov.u32 %r32, 0;
setp.eq.s32	%p2, %r20, 0;
@%p2 bra BB0_7;

setp.eq.s32	%p3, %r20, 1;
@%p3 bra BB0_6;

setp.eq.s32	%p4, %r20, 2;
@%p4 bra BB0_5;

mul.wide.s32 %rd22, %r3, 8;
add.s64 %rd23, %rd2, %rd22;
mul.wide.s32 %rd24, %r2, 8;
add.s64 %rd25, %rd1, %rd24;
ld.global.u64 %rd26, [%rd25];
ld.global.u64 %rd27, [%rd23];
mul.lo.s64 %rd72, %rd26, %rd27;
mov.u32 %r32, 1;

BB0_5:
add.s32 %r22, %r32, %r3;
mul.wide.s32 %rd28, %r22, 8;
add.s64 %rd29, %rd2, %rd28;
neg.s32 %r23, %r32;
and.b32 %r24, %r23, %r16;
add.s32 %r25, %r24, %r2;
mul.wide.s32 %rd30, %r25, 8;
add.s64 %rd31, %rd1, %rd30;
ld.global.u64 %rd32, [%rd31];
ld.global.u64 %rd33, [%rd29];
mul.lo.s64 %rd34, %rd32, %rd33;
add.s64 %rd72, %rd34, %rd72;
add.s32 %r32, %r32, 1;

BB0_6:
add.s32 %r26, %r32, %r3;
mul.wide.s32 %rd35, %r26, 8;
add.s64 %rd36, %rd2, %rd35;
mad.lo.s32 %r27, %r32, %r16, %r2;
mul.wide.s32 %rd37, %r27, 8;
add.s64 %rd38, %rd1, %rd37;
ld.global.u64 %rd39, [%rd38];
ld.global.u64 %rd40, [%rd36];
mul.lo.s64 %rd41, %rd39, %rd40;
add.s64 %rd72, %rd41, %rd72;
add.s32 %r32, %r32, 1;

BB0_7:
setp.lt.u32	%p5, %r16, 4;
@%p5 bra BB0_10;

shl.b32 %r9, %r16, 2;
mad.lo.s32 %r28, %r1, %r16, %r32;
mul.wide.s32 %rd42, %r28, 8;
add.s64 %rd70, %rd2, %rd42;
mad.lo.s32 %r33, %r32, %r16, %r2;
shl.b32 %r11, %r16, 3;

BB0_9:
mul.wide.s32 %rd43, %r33, 8;
add.s64 %rd44, %rd1, %rd43;
ld.global.u64 %rd45, [%rd44];
ld.global.u64 %rd46, [%rd70];
mul.lo.s64 %rd47, %rd45, %rd46;
add.s64 %rd48, %rd47, %rd72;
cvt.s64.s32	%rd49, %r11;
add.s64 %rd50, %rd44, %rd49;
ld.global.u64 %rd51, [%rd50];
ld.global.u64 %rd52, [%rd70+8];
mul.lo.s64 %rd53, %rd51, %rd52;
add.s64 %rd54, %rd53, %rd48;
add.s64 %rd55, %rd50, %rd49;
ld.global.u64 %rd56, [%rd55];
ld.global.u64 %rd57, [%rd70+16];
mul.lo.s64 %rd58, %rd56, %rd57;
add.s64 %rd59, %rd58, %rd54;
add.s64 %rd60, %rd55, %rd49;
ld.global.u64 %rd61, [%rd60];
ld.global.u64 %rd62, [%rd70+24];
mul.lo.s64 %rd63, %rd61, %rd62;
add.s64 %rd72, %rd63, %rd59;
add.s64 %rd70, %rd70, 32;
add.s32 %r33, %r33, %r9;
add.s32 %r32, %r32, 4;
setp.lt.s32	%p6, %r32, %r16;
@%p6 bra BB0_9;

BB0_10:
cvta.to.global.u64 %rd64, %rd15;
mad.lo.s32 %r29, %r1, 10, %r2;
mul.wide.s32 %rd65, %r29, 8;
add.s64 %rd66, %rd64, %rd65;
st.global.u64 [%rd66], %rd72;
ret;
}


